{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def init_neural_network(lambd=0.10):\n",
    "    # Initialise keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Add convolutional network layers\n",
    "    # Input layer, [3x3 2D convolution, with 3 filters,\n",
    "    # followed by a 2x2 max pooling layer]\n",
    "    model.add(tf.keras.layers.Conv2D(3, (3,3), strides=(1,1), padding='valid',\n",
    "                                     activation = 'relu', input_shape=(22, 22, 1),\n",
    "                                     kernel_regularizer=keras.regularizers.l2(lambd)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=None, padding='valid'))\n",
    "    \n",
    "    # 2nd layer, [3x3 2D convolution, with 6 filters,\n",
    "    # followed by a 2x2 max pooling layer]\n",
    "    model.add(tf.keras.layers.Conv2D(6, (3,3), strides=(1,1), padding='valid',\n",
    "                                     activation = 'relu',\n",
    "                                     kernel_regularizer=keras.regularizers.l2(lambd)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=None, padding='valid'))\n",
    "    \n",
    "    # Flatten to a 1 dimensional layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # 3rd layer, 22 unit dense connected layer\n",
    "    model.add(tf.keras.layers.Dense(22, activation='relu'))\n",
    "    \n",
    "    # Output layer into a single sigmoid unit\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model, [using stochastic gradient descent optimiser,\n",
    "    # and binary crossentropy loss function]\n",
    "    model.compile('SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_training_data(dir_path):\n",
    "    \"\"\"Docstring...\n",
    "    \"\"\"\n",
    "    # Initialize numpy array of appropriate dimensions\n",
    "    examples = np.ndarray((1, 22, 22))\n",
    "    # Loop through files in training segments directory\n",
    "    for dirname, _, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            # Import files as numpy arrays\n",
    "            path = os.path.join(dirname, filename)\n",
    "            example = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            example_reshaped = np.reshape(example ,(1, 22, 22))\n",
    "            # Synthesize training examples by laterally inverting images\n",
    "            example_flipped = cv2.flip(example, 1)\n",
    "            example_flipped_reshaped = np.reshape(example_flipped ,(1, 22, 22))\n",
    "            # Concatenate examples into one numpy array\n",
    "            examples = np.concatenate((examples, example_reshaped), axis=0)\n",
    "            examples = np.concatenate((examples, example_flipped_reshaped), axis=0)\n",
    "            \n",
    "    # Delete the first row of zeros created when examples array was initialised\n",
    "    examples = np.delete(examples, (0), axis=0)\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and format data\n",
    "path_pos = '/kaggle/input/positive-seg-examples/training_segments_positive'\n",
    "pos_examples = import_training_data(path_pos)\n",
    "\n",
    "path_neg = '/kaggle/input/negative-seg-examples/training_segments_negative'\n",
    "neg_examples = import_training_data(path_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets\n",
    "data = np.concatenate((pos_examples, neg_examples), axis=0)\n",
    "X = np.reshape(data, (data.shape[0], 22, 22, 1))\n",
    "\n",
    "# Make labels for concatenated image matrix\n",
    "labels = np.concatenate((np.ones((pos_examples.shape[0], 1)),\n",
    "                         np.zeros((neg_examples.shape[0], 1))), axis=0)\n",
    "\n",
    "# Feature scale pixel values\n",
    "X = data / 255\n",
    "# Format image data to be keras readable\n",
    "X = np.reshape(X, (X.shape[0], 22, 22, 1))\n",
    "\n",
    "# Shuffle data, seeding so it shuffles labels and images together\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(X)\n",
    "np.random.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2257 samples, validate on 251 samples\n",
      "Epoch 1/50\n",
      "2257/2257 [==============================] - 1s 342us/sample - loss: 0.6898 - acc: 0.6052 - val_loss: 0.6824 - val_acc: 0.6534\n",
      "Epoch 2/50\n",
      "2257/2257 [==============================] - 0s 216us/sample - loss: 0.6827 - acc: 0.6088 - val_loss: 0.6747 - val_acc: 0.6534\n",
      "Epoch 3/50\n",
      "2257/2257 [==============================] - 0s 207us/sample - loss: 0.6783 - acc: 0.6088 - val_loss: 0.6686 - val_acc: 0.6534\n",
      "Epoch 4/50\n",
      "2257/2257 [==============================] - 1s 229us/sample - loss: 0.6749 - acc: 0.6088 - val_loss: 0.6638 - val_acc: 0.6534\n",
      "Epoch 5/50\n",
      "2257/2257 [==============================] - 0s 206us/sample - loss: 0.6724 - acc: 0.6088 - val_loss: 0.6601 - val_acc: 0.6534\n",
      "Epoch 6/50\n",
      "2257/2257 [==============================] - 0s 209us/sample - loss: 0.6705 - acc: 0.6088 - val_loss: 0.6570 - val_acc: 0.6534\n",
      "Epoch 7/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.6688 - acc: 0.6088 - val_loss: 0.6543 - val_acc: 0.6534\n",
      "Epoch 8/50\n",
      "2257/2257 [==============================] - 0s 212us/sample - loss: 0.6674 - acc: 0.6088 - val_loss: 0.6521 - val_acc: 0.6534\n",
      "Epoch 9/50\n",
      "2257/2257 [==============================] - 1s 224us/sample - loss: 0.6662 - acc: 0.6088 - val_loss: 0.6504 - val_acc: 0.6534\n",
      "Epoch 10/50\n",
      "2257/2257 [==============================] - 0s 211us/sample - loss: 0.6653 - acc: 0.6088 - val_loss: 0.6490 - val_acc: 0.6534\n",
      "Epoch 11/50\n",
      "2257/2257 [==============================] - 0s 211us/sample - loss: 0.6644 - acc: 0.6088 - val_loss: 0.6477 - val_acc: 0.6534\n",
      "Epoch 12/50\n",
      "2257/2257 [==============================] - 0s 214us/sample - loss: 0.6636 - acc: 0.6088 - val_loss: 0.6463 - val_acc: 0.6534\n",
      "Epoch 13/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.6627 - acc: 0.6088 - val_loss: 0.6451 - val_acc: 0.6534\n",
      "Epoch 14/50\n",
      "2257/2257 [==============================] - 0s 209us/sample - loss: 0.6618 - acc: 0.6088 - val_loss: 0.6438 - val_acc: 0.6534\n",
      "Epoch 15/50\n",
      "2257/2257 [==============================] - 0s 207us/sample - loss: 0.6607 - acc: 0.6088 - val_loss: 0.6424 - val_acc: 0.6534\n",
      "Epoch 16/50\n",
      "2257/2257 [==============================] - 0s 209us/sample - loss: 0.6594 - acc: 0.6088 - val_loss: 0.6412 - val_acc: 0.6534\n",
      "Epoch 17/50\n",
      "2257/2257 [==============================] - 0s 206us/sample - loss: 0.6579 - acc: 0.6088 - val_loss: 0.6393 - val_acc: 0.6534\n",
      "Epoch 18/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.6561 - acc: 0.6088 - val_loss: 0.6373 - val_acc: 0.6534\n",
      "Epoch 19/50\n",
      "2257/2257 [==============================] - 0s 212us/sample - loss: 0.6538 - acc: 0.6088 - val_loss: 0.6352 - val_acc: 0.6534\n",
      "Epoch 20/50\n",
      "2257/2257 [==============================] - 0s 212us/sample - loss: 0.6511 - acc: 0.6088 - val_loss: 0.6319 - val_acc: 0.6534\n",
      "Epoch 21/50\n",
      "2257/2257 [==============================] - 0s 214us/sample - loss: 0.6474 - acc: 0.6088 - val_loss: 0.6287 - val_acc: 0.6534\n",
      "Epoch 22/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.6428 - acc: 0.6088 - val_loss: 0.6235 - val_acc: 0.6534\n",
      "Epoch 23/50\n",
      "2257/2257 [==============================] - 0s 207us/sample - loss: 0.6366 - acc: 0.6088 - val_loss: 0.6169 - val_acc: 0.6534\n",
      "Epoch 24/50\n",
      "2257/2257 [==============================] - 0s 213us/sample - loss: 0.6283 - acc: 0.6097 - val_loss: 0.6081 - val_acc: 0.6534\n",
      "Epoch 25/50\n",
      "2257/2257 [==============================] - 0s 219us/sample - loss: 0.6166 - acc: 0.6261 - val_loss: 0.5968 - val_acc: 0.7052\n",
      "Epoch 26/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.5999 - acc: 0.6992 - val_loss: 0.5778 - val_acc: 0.7450\n",
      "Epoch 27/50\n",
      "2257/2257 [==============================] - 0s 212us/sample - loss: 0.5762 - acc: 0.7696 - val_loss: 0.5531 - val_acc: 0.8088\n",
      "Epoch 28/50\n",
      "2257/2257 [==============================] - 0s 211us/sample - loss: 0.5441 - acc: 0.8263 - val_loss: 0.5370 - val_acc: 0.8685\n",
      "Epoch 29/50\n",
      "2257/2257 [==============================] - 0s 215us/sample - loss: 0.5017 - acc: 0.8844 - val_loss: 0.4809 - val_acc: 0.9084\n",
      "Epoch 30/50\n",
      "2257/2257 [==============================] - 1s 223us/sample - loss: 0.4562 - acc: 0.9149 - val_loss: 0.4431 - val_acc: 0.9084\n",
      "Epoch 31/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.4117 - acc: 0.9366 - val_loss: 0.3897 - val_acc: 0.9522\n",
      "Epoch 32/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.3721 - acc: 0.9508 - val_loss: 0.3531 - val_acc: 0.9681\n",
      "Epoch 33/50\n",
      "2257/2257 [==============================] - 0s 209us/sample - loss: 0.3399 - acc: 0.9575 - val_loss: 0.3185 - val_acc: 0.9681\n",
      "Epoch 34/50\n",
      "2257/2257 [==============================] - 0s 207us/sample - loss: 0.3132 - acc: 0.9597 - val_loss: 0.2911 - val_acc: 0.9721\n",
      "Epoch 35/50\n",
      "2257/2257 [==============================] - 0s 203us/sample - loss: 0.2885 - acc: 0.9694 - val_loss: 0.2665 - val_acc: 0.9761\n",
      "Epoch 36/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.2671 - acc: 0.9703 - val_loss: 0.2505 - val_acc: 0.9721\n",
      "Epoch 37/50\n",
      "2257/2257 [==============================] - 0s 213us/sample - loss: 0.2501 - acc: 0.9747 - val_loss: 0.2332 - val_acc: 0.9721\n",
      "Epoch 38/50\n",
      "2257/2257 [==============================] - 0s 209us/sample - loss: 0.2375 - acc: 0.9739 - val_loss: 0.2175 - val_acc: 0.9761\n",
      "Epoch 39/50\n",
      "2257/2257 [==============================] - 0s 204us/sample - loss: 0.2256 - acc: 0.9752 - val_loss: 0.2060 - val_acc: 0.9801\n",
      "Epoch 40/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.2146 - acc: 0.9770 - val_loss: 0.2121 - val_acc: 0.9801\n",
      "Epoch 41/50\n",
      "2257/2257 [==============================] - 0s 204us/sample - loss: 0.2057 - acc: 0.9796 - val_loss: 0.1855 - val_acc: 0.9801\n",
      "Epoch 42/50\n",
      "2257/2257 [==============================] - 0s 207us/sample - loss: 0.1975 - acc: 0.9801 - val_loss: 0.1773 - val_acc: 0.9801\n",
      "Epoch 43/50\n",
      "2257/2257 [==============================] - 0s 208us/sample - loss: 0.1898 - acc: 0.9814 - val_loss: 0.1741 - val_acc: 0.9801\n",
      "Epoch 44/50\n",
      "2257/2257 [==============================] - 0s 206us/sample - loss: 0.1828 - acc: 0.9796 - val_loss: 0.1620 - val_acc: 0.9801\n",
      "Epoch 45/50\n",
      "2257/2257 [==============================] - 0s 203us/sample - loss: 0.1769 - acc: 0.9805 - val_loss: 0.1545 - val_acc: 0.9801\n",
      "Epoch 46/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.1712 - acc: 0.9805 - val_loss: 0.1567 - val_acc: 0.9801\n",
      "Epoch 47/50\n",
      "2257/2257 [==============================] - 0s 200us/sample - loss: 0.1665 - acc: 0.9814 - val_loss: 0.1435 - val_acc: 0.9801\n",
      "Epoch 48/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.1608 - acc: 0.9823 - val_loss: 0.1382 - val_acc: 0.9801\n",
      "Epoch 49/50\n",
      "2257/2257 [==============================] - 0s 205us/sample - loss: 0.1565 - acc: 0.9809 - val_loss: 0.1369 - val_acc: 0.9841\n",
      "Epoch 50/50\n",
      "2257/2257 [==============================] - 0s 211us/sample - loss: 0.1527 - acc: 0.9832 - val_loss: 0.1321 - val_acc: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f553070cef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and save model\n",
    "model = init_neural_network(lambd=0)\n",
    "model.fit(X, labels, epochs=50, validation_split=0.10)\n",
    "model.save('/kaggle/working/test_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}